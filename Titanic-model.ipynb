{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To have plot inline with jupyter notebook\n",
    "% matplotlib inline\n",
    "\n",
    "# Import Default dictionary\n",
    "from collections import defaultdict\n",
    "\n",
    "# Machine Learning models\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# K-Nearest Neighbour\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Naive-Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Support Vector classifier\n",
    "from sklearn.svm import NuSVC\n",
    "\n",
    "# Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test dataset\n",
    "df_titan_train = pd.read_csv(\"Titanic/df_train.csv\")\n",
    "df_titan_test = pd.read_csv(\"Titanic/df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________\n",
      "Training Dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 33 columns):\n",
      "PassengerId               891 non-null int64\n",
      "Survived                  891 non-null int64\n",
      "Pclass_1                  891 non-null int64\n",
      "Pclass_2                  891 non-null int64\n",
      "Pclass_3                  891 non-null int64\n",
      "Embarked_C                891 non-null int64\n",
      "Embarked_Q                891 non-null int64\n",
      "Embarked_S                891 non-null int64\n",
      "Sex_title_female Miss.    891 non-null int64\n",
      "Sex_title_female Mrs.     891 non-null int64\n",
      "Sex_title_female rare     891 non-null int64\n",
      "Sex_title_male Master.    891 non-null int64\n",
      "Sex_title_male Mr.        891 non-null int64\n",
      "Sex_title_male rare       891 non-null int64\n",
      "Agegrp_0                  891 non-null int64\n",
      "Agegrp_1                  891 non-null int64\n",
      "Agegrp_2                  891 non-null int64\n",
      "Agegrp_3                  891 non-null int64\n",
      "Agegrp_4                  891 non-null int64\n",
      "Agegrp_5                  891 non-null int64\n",
      "Sibsize_0                 891 non-null int64\n",
      "Sibsize_1                 891 non-null int64\n",
      "Sibsize_2                 891 non-null int64\n",
      "Sibsize_3                 891 non-null int64\n",
      "Parsize_0                 891 non-null int64\n",
      "Parsize_1                 891 non-null int64\n",
      "Parsize_2                 891 non-null int64\n",
      "Faregrp_0                 891 non-null int64\n",
      "Faregrp_1                 891 non-null int64\n",
      "Faregrp_2                 891 non-null int64\n",
      "Faregrp_3                 891 non-null int64\n",
      "Faregrp_4                 891 non-null int64\n",
      "Faregrp_5                 891 non-null int64\n",
      "dtypes: int64(33)\n",
      "memory usage: 229.8 KB\n",
      "________________________________________\n",
      "________________________________________\n",
      "Test Dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 32 columns):\n",
      "PassengerId               418 non-null int64\n",
      "Pclass_1                  418 non-null int64\n",
      "Pclass_2                  418 non-null int64\n",
      "Pclass_3                  418 non-null int64\n",
      "Embarked_C                418 non-null int64\n",
      "Embarked_Q                418 non-null int64\n",
      "Embarked_S                418 non-null int64\n",
      "Sex_title_female Miss.    418 non-null int64\n",
      "Sex_title_female Mrs.     418 non-null int64\n",
      "Sex_title_female rare     418 non-null int64\n",
      "Sex_title_male Master.    418 non-null int64\n",
      "Sex_title_male Mr.        418 non-null int64\n",
      "Sex_title_male rare       418 non-null int64\n",
      "Agegrp_0                  418 non-null int64\n",
      "Agegrp_1                  418 non-null int64\n",
      "Agegrp_2                  418 non-null int64\n",
      "Agegrp_3                  418 non-null int64\n",
      "Agegrp_4                  418 non-null int64\n",
      "Agegrp_5                  418 non-null int64\n",
      "Sibsize_0                 418 non-null int64\n",
      "Sibsize_1                 418 non-null int64\n",
      "Sibsize_2                 418 non-null int64\n",
      "Sibsize_3                 418 non-null int64\n",
      "Parsize_0                 418 non-null int64\n",
      "Parsize_1                 418 non-null int64\n",
      "Parsize_2                 418 non-null int64\n",
      "Faregrp_0                 418 non-null int64\n",
      "Faregrp_1                 418 non-null int64\n",
      "Faregrp_2                 418 non-null int64\n",
      "Faregrp_3                 418 non-null int64\n",
      "Faregrp_4                 418 non-null int64\n",
      "Faregrp_5                 418 non-null int64\n",
      "dtypes: int64(32)\n",
      "memory usage: 104.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Get basic information from both the datasets\n",
    "print('_'*40)\n",
    "print('Training Dataset')\n",
    "df_titan_train.info()\n",
    "print('_'*40)\n",
    "print('_'*40)\n",
    "print('Test Dataset')\n",
    "df_titan_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features :Index(['PassengerId', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S', 'Sex_title_female Miss.',\n",
      "       'Sex_title_female Mrs.', 'Sex_title_female rare',\n",
      "       'Sex_title_male Master.', 'Sex_title_male Mr.', 'Sex_title_male rare',\n",
      "       'Agegrp_0', 'Agegrp_1', 'Agegrp_2', 'Agegrp_3', 'Agegrp_4', 'Agegrp_5',\n",
      "       'Sibsize_0', 'Sibsize_1', 'Sibsize_2', 'Sibsize_3', 'Parsize_0',\n",
      "       'Parsize_1', 'Parsize_2', 'Faregrp_0', 'Faregrp_1', 'Faregrp_2',\n",
      "       'Faregrp_3', 'Faregrp_4', 'Faregrp_5'],\n",
      "      dtype='object') \n",
      "\n",
      "Labels :Survived\n"
     ]
    }
   ],
   "source": [
    "# Features and labels\n",
    "features = df_titan_test.columns\n",
    "label = 'Survived'\n",
    "print(\"Features :{} \\n\\nLabels :{}\".format(features,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q',\n",
       "       'Embarked_S', 'Sex_title_female Miss.', 'Sex_title_female Mrs.',\n",
       "       'Sex_title_female rare', 'Sex_title_male Master.', 'Sex_title_male Mr.',\n",
       "       'Sex_title_male rare', 'Agegrp_0', 'Agegrp_1', 'Agegrp_2', 'Agegrp_3',\n",
       "       'Agegrp_4', 'Agegrp_5', 'Sibsize_0', 'Sibsize_1', 'Sibsize_2',\n",
       "       'Sibsize_3', 'Parsize_0', 'Parsize_1', 'Parsize_2', 'Faregrp_0',\n",
       "       'Faregrp_1', 'Faregrp_2', 'Faregrp_3', 'Faregrp_4', 'Faregrp_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features required for model\n",
    "model_features = features[1:]\n",
    "model_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - train, test and predict\n",
    "def classifier(X, Y, mod, params, mode = 'train') :\n",
    "    \n",
    "    if mode == 'train' :\n",
    "        if params == None :\n",
    "            model = mod()\n",
    "        else :\n",
    "            model = mod(**params)\n",
    "        Info = model.fit(X,Y)\n",
    "    elif mode == 'test' or mode == 'predict' :\n",
    "        model = mod\n",
    "        Info = None\n",
    "        \n",
    "    Prediction = model.predict(X)\n",
    "    \n",
    "    if mode == 'train' or mode == 'test' :\n",
    "        Accuracy = round(model.score(X,Y)*100,2)        \n",
    "    elif mode == 'predict' :\n",
    "        Accuracy = None\n",
    "    \n",
    "    return(Info, model, Prediction, Accuracy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to test\n",
    "models = {\n",
    "          'Logistic Regression' : LogisticRegression ,\n",
    "          'K-Nearest Neighbour' : KNeighborsClassifier ,\n",
    "          'Naive Bayes' : GaussianNB ,\n",
    "          'Decision Tree' : DecisionTreeClassifier ,\n",
    "          'Support Vector Machine' : NuSVC ,\n",
    "          'Random Forest Classifier' : RandomForestClassifier\n",
    "         }\n",
    "\n",
    "# Model parameters\n",
    "model_params = {\n",
    "          'Logistic Regression' : [None] ,\n",
    "          'K-Nearest Neighbour' : [None, {'n_neighbors' : 3}, {'n_neighbors' : 5}] ,\n",
    "          'Naive Bayes' : [None] ,\n",
    "          'Decision Tree' : [None] ,\n",
    "          'Support Vector Machine' : [None, {'kernel':'linear'}, {'kernel':'poly'}, {'kernel':'sigmoid'}] ,\n",
    "          'Random Forest Classifier' : [None, {'n_estimators':50},{'n_estimators':100},{'n_estimators':500}]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all the models\n",
    "X_train = df_titan_train[model_features]\n",
    "Y_train = df_titan_train[label]\n",
    "X_test = df_titan_test[model_features]\n",
    "Info = defaultdict(dict); Model =defaultdict(dict); Train_prediction = defaultdict(dict)\n",
    "Train_acc = defaultdict(dict);  parameters = defaultdict(dict)\n",
    "for name, mod in models.items() :    \n",
    "    for key, params in enumerate(model_params[name]) :             \n",
    "        parameters[name][key] = params\n",
    "        Info[name][key], Model[name][key], Train_prediction[name][key], Train_acc[name][key], \\\n",
    "                    = classifier(X_train, Y_train, mod, params, mode ='train')            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Random Forest Classifier\n",
      "Parameters passed \t\t :  {'n_estimators': 50}\n",
      "Training Accuracy \t\t :  89.23 %\n",
      "Model info \t\t\t :  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Random Forest Classifier\n",
      "Parameters passed \t\t :  {'n_estimators': 100}\n",
      "Training Accuracy \t\t :  89.23 %\n",
      "Model info \t\t\t :  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Random Forest Classifier\n",
      "Parameters passed \t\t :  {'n_estimators': 500}\n",
      "Training Accuracy \t\t :  89.23 %\n",
      "Model info \t\t\t :  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Decision Tree\n",
      "Parameters passed \t\t :  None\n",
      "Training Accuracy \t\t :  89.23 %\n",
      "Model info \t\t\t :  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Random Forest Classifier\n",
      "Parameters passed \t\t :  None\n",
      "Training Accuracy \t\t :  88.66 %\n",
      "Model info \t\t\t :  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  K-Nearest Neighbour\n",
      "Parameters passed \t\t :  {'n_neighbors': 3}\n",
      "Training Accuracy \t\t :  85.19 %\n",
      "Model info \t\t\t :  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  K-Nearest Neighbour\n",
      "Parameters passed \t\t :  None\n",
      "Training Accuracy \t\t :  83.84 %\n",
      "Model info \t\t\t :  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  K-Nearest Neighbour\n",
      "Parameters passed \t\t :  {'n_neighbors': 5}\n",
      "Training Accuracy \t\t :  83.84 %\n",
      "Model info \t\t\t :  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Support Vector Machine\n",
      "Parameters passed \t\t :  {'kernel': 'poly'}\n",
      "Training Accuracy \t\t :  83.73 %\n",
      "Model info \t\t\t :  NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "   max_iter=-1, nu=0.5, probability=False, random_state=None,\n",
      "   shrinking=True, tol=0.001, verbose=False)\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Logistic Regression\n",
      "Parameters passed \t\t :  None\n",
      "Training Accuracy \t\t :  82.94 %\n",
      "Model info \t\t\t :  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Support Vector Machine\n",
      "Parameters passed \t\t :  None\n",
      "Training Accuracy \t\t :  82.49 %\n",
      "Model info \t\t\t :  NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "   max_iter=-1, nu=0.5, probability=False, random_state=None,\n",
      "   shrinking=True, tol=0.001, verbose=False)\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Support Vector Machine\n",
      "Parameters passed \t\t :  {'kernel': 'sigmoid'}\n",
      "Training Accuracy \t\t :  82.04 %\n",
      "Model info \t\t\t :  NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "   max_iter=-1, nu=0.5, probability=False, random_state=None,\n",
      "   shrinking=True, tol=0.001, verbose=False)\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Support Vector Machine\n",
      "Parameters passed \t\t :  {'kernel': 'linear'}\n",
      "Training Accuracy \t\t :  81.71 %\n",
      "Model info \t\t\t :  NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "   max_iter=-1, nu=0.5, probability=False, random_state=None,\n",
      "   shrinking=True, tol=0.001, verbose=False)\n",
      "******************************************************************************************\n",
      "Model \t\t\t\t :  Naive Bayes\n",
      "Parameters passed \t\t :  None\n",
      "Training Accuracy \t\t :  76.88 %\n",
      "Model info \t\t\t :  GaussianNB(priors=None)\n"
     ]
    }
   ],
   "source": [
    "# Store the accuracy of the model\n",
    "i=0\n",
    "df_model_score = pd.DataFrame(columns = ['Name', 'key','Parameters','Info','Train_acc'])\n",
    "for name, _ in models.items() :    \n",
    "    for key, params in enumerate(model_params[name]) :      \n",
    "        df_model_score.loc[i] = [name,key,params,Info[name][key],Train_acc[name][key]]\n",
    "        i+=1\n",
    "                                  \n",
    "# Print the output in the order of Training accuracy\n",
    "for index, row in df_model_score.sort_values(['Train_acc'],ascending=False).iterrows() :\n",
    "    print('*'*90)\n",
    "    print(\"Model \\t\\t\\t\\t : \",row[0])\n",
    "    print(\"Parameters passed \\t\\t : \",row[2])\n",
    "    print('Training Accuracy \\t\\t : ',row[4],'%')\n",
    "    print('Model info \\t\\t\\t : ',row[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>key</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>89.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>89.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "      <td>89.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>89.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>88.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbour</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>85.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest Neighbour</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>83.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbour</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>83.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>2</td>\n",
       "      <td>{'kernel': 'poly'}</td>\n",
       "      <td>83.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>82.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>82.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>3</td>\n",
       "      <td>{'kernel': 'sigmoid'}</td>\n",
       "      <td>82.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>1</td>\n",
       "      <td>{'kernel': 'linear'}</td>\n",
       "      <td>81.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>76.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name key             Parameters  Train_acc\n",
       "8   Random Forest Classifier   1   {'n_estimators': 50}      89.23\n",
       "9   Random Forest Classifier   2  {'n_estimators': 100}      89.23\n",
       "10  Random Forest Classifier   3  {'n_estimators': 500}      89.23\n",
       "12             Decision Tree   0                   None      89.23\n",
       "7   Random Forest Classifier   0                   None      88.66\n",
       "1        K-Nearest Neighbour   1     {'n_neighbors': 3}      85.19\n",
       "0        K-Nearest Neighbour   0                   None      83.84\n",
       "2        K-Nearest Neighbour   2     {'n_neighbors': 5}      83.84\n",
       "5     Support Vector Machine   2     {'kernel': 'poly'}      83.73\n",
       "13       Logistic Regression   0                   None      82.94\n",
       "3     Support Vector Machine   0                   None      82.49\n",
       "6     Support Vector Machine   3  {'kernel': 'sigmoid'}      82.04\n",
       "4     Support Vector Machine   1   {'kernel': 'linear'}      81.71\n",
       "11               Naive Bayes   0                   None      76.88"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se all the output in tabular form (in the order of training data accuracy)\n",
    "df_model_score.sort_values(['Train_acc'],ascending=False).iloc[:,[0,1,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name\n",
       "8   Random Forest Classifier\n",
       "12             Decision Tree\n",
       "2        K-Nearest Neighbour\n",
       "5     Support Vector Machine\n",
       "13       Logistic Regression"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets pick 5 models \n",
    "Indexes = [8,12,2,5,13] \n",
    "df_model_score.loc[Indexes,['Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now do cross validation\n",
    "Info = {}; Model ={}; Train_prediction = {}; Train_acc = {};  parameters = {}\n",
    "kfld = StratifiedKFold(n_splits=10,random_state=123)\n",
    "for trcv_index, tscv_index in skf.split(X_train, Y_train):\n",
    "    X_trcv, X_tscv = X_train[trcv_index], X_train[tscv_index]\n",
    "    Y_trcv, y_tscv = Y_train[trcv_index], Y_train[tscv_index]\n",
    "    for name in Indexes :    \n",
    "        Info[name], Model[name], Train_prediction[name], Train_acc[name], \\\n",
    "                        = classifier(X_trcv, Y_trcv, Model[name], parameters[name],mode='train')            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = np.zeros(shape=X_train.shape[0])\n",
    "for ind in Indexes :\n",
    "    final_prediction += Train_prediction[ind]/len(Indexes)\n",
    "\n",
    "final_prediction=1*(final_prediction > 0.5)\n",
    "sum(final_prediction == Y_train)/Y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-128-2c7f2e128275>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-128-2c7f2e128275>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    parameters[][]\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "parameters[][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
